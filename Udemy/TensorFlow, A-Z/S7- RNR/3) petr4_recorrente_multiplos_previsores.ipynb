{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4119d6b4-bcb2-42e8-bb9f-00a3d6436516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3657288-24cf-4d2d-9b8d-3cbb7bd0120f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>19.990000</td>\n",
       "      <td>20.209999</td>\n",
       "      <td>19.690001</td>\n",
       "      <td>19.690001</td>\n",
       "      <td>18.086271</td>\n",
       "      <td>30182600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>19.809999</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>18.738441</td>\n",
       "      <td>30552600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>20.330000</td>\n",
       "      <td>20.620001</td>\n",
       "      <td>20.170000</td>\n",
       "      <td>20.430000</td>\n",
       "      <td>18.766001</td>\n",
       "      <td>36141000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close  \\\n",
       "0  2013-01-02  19.990000  20.209999  19.690001  19.690001  18.086271   \n",
       "1  2013-01-03  19.809999  20.400000  19.700001  20.400000  18.738441   \n",
       "2  2013-01-04  20.330000  20.620001  20.170000  20.430000  18.766001   \n",
       "\n",
       "       Volume  \n",
       "0  30182600.0  \n",
       "1  30552600.0  \n",
       "2  36141000.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = pd.read_csv('petr4_treinamento.csv')\n",
    "base = base.dropna()\n",
    "base.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "406d3821-4596-487a-a630-32fa49848140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>15.99</td>\n",
       "      <td>16.139999</td>\n",
       "      <td>15.98</td>\n",
       "      <td>16.049999</td>\n",
       "      <td>16.017963</td>\n",
       "      <td>23552200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>16.10</td>\n",
       "      <td>16.129999</td>\n",
       "      <td>16.00</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>16.067865</td>\n",
       "      <td>19011500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>16.10</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>16.10</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>16.067865</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date   Open       High    Low      Close  Adj Close      Volume\n",
       "1242  2017-12-27  15.99  16.139999  15.98  16.049999  16.017963  23552200.0\n",
       "1243  2017-12-28  16.10  16.129999  16.00  16.100000  16.067865  19011500.0\n",
       "1244  2017-12-29  16.10  16.100000  16.10  16.100000  16.067865         0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd490f76-6748-4685-9907-dba9562a6e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_treinamento = base.iloc[:, 1:7].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "770f1ffb-f37b-45c9-8739-5a88fa585ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.76501938],\n",
       "       [0.7562984 ],\n",
       "       [0.78149225],\n",
       "       ...,\n",
       "       [0.57122093],\n",
       "       [0.57655039],\n",
       "       [0.57655039]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizador = MinMaxScaler(feature_range=(0,1))\n",
    "base_treinamento_normalizada = normalizador.fit_transform(base_treinamento)\n",
    "\n",
    "normalizador_previsao = MinMaxScaler(feature_range=(0,1))\n",
    "normalizador_previsao.fit_transform(base_treinamento[:,0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1594516a-52f7-49de-9193-1c1da1460adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1242, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80e0217c-8a2d-4205-be0a-554ee5f7684a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1242, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_treinamento_normalizada.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da18a3bb-2d5f-4cd5-b173-b65bca6ac0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1152, 90, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsores = []\n",
    "preco_real = []\n",
    "for i in range(90, 1242):\n",
    "    previsores.append(base_treinamento_normalizada[i-90:i, 0:6])\n",
    "    preco_real.append(base_treinamento_normalizada[i, 0])\n",
    "previsores, preco_real = np.array(previsores), np.array(preco_real)\n",
    "previsores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6724b50-c52b-42ad-89ad-0f2c4db7b544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 90, 100)           42800     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 90, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 90, 50)            30200     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 90, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 90, 50)            20200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 90, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 113,451\n",
      "Trainable params: 113,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "regressor = Sequential()\n",
    "regressor.add(LSTM(units = 100, return_sequences = True, input_shape = (previsores.shape[1], 6)))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "regressor.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error',\n",
    "                  metrics = ['mean_absolute_error'])\n",
    "\n",
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca88473d-0ee2-4bcd-91cb-e4906f3fb642",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0163 - mean_absolute_error: 0.0947\n",
      "Epoch 00001: loss improved from inf to 0.01627, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 144ms/step - loss: 0.0163 - mean_absolute_error: 0.0947\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0052 - mean_absolute_error: 0.0563\n",
      "Epoch 00002: loss improved from 0.01627 to 0.00516, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 136ms/step - loss: 0.0052 - mean_absolute_error: 0.0563\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0041 - mean_absolute_error: 0.0500\n",
      "Epoch 00003: loss improved from 0.00516 to 0.00409, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 136ms/step - loss: 0.0041 - mean_absolute_error: 0.0500\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0040 - mean_absolute_error: 0.0496\n",
      "Epoch 00004: loss improved from 0.00409 to 0.00397, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.0040 - mean_absolute_error: 0.0496\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0036 - mean_absolute_error: 0.0469\n",
      "Epoch 00005: loss improved from 0.00397 to 0.00363, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 138ms/step - loss: 0.0036 - mean_absolute_error: 0.0469\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0031 - mean_absolute_error: 0.0430\n",
      "Epoch 00006: loss improved from 0.00363 to 0.00311, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 138ms/step - loss: 0.0031 - mean_absolute_error: 0.0430\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0033 - mean_absolute_error: 0.0447\n",
      "Epoch 00007: loss did not improve from 0.00311\n",
      "36/36 [==============================] - 5s 137ms/step - loss: 0.0033 - mean_absolute_error: 0.0447\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0031 - mean_absolute_error: 0.0424\n",
      "Epoch 00008: loss improved from 0.00311 to 0.00305, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 138ms/step - loss: 0.0031 - mean_absolute_error: 0.0424\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0028 - mean_absolute_error: 0.0408\n",
      "Epoch 00009: loss improved from 0.00305 to 0.00280, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 137ms/step - loss: 0.0028 - mean_absolute_error: 0.0408\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0025 - mean_absolute_error: 0.0378\n",
      "Epoch 00010: loss improved from 0.00280 to 0.00246, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 144ms/step - loss: 0.0025 - mean_absolute_error: 0.0378\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0022 - mean_absolute_error: 0.0363\n",
      "Epoch 00011: loss improved from 0.00246 to 0.00225, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 140ms/step - loss: 0.0022 - mean_absolute_error: 0.0363\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0027 - mean_absolute_error: 0.0396\n",
      "Epoch 00012: loss did not improve from 0.00225\n",
      "36/36 [==============================] - 5s 136ms/step - loss: 0.0027 - mean_absolute_error: 0.0396\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0022 - mean_absolute_error: 0.0359\n",
      "Epoch 00013: loss improved from 0.00225 to 0.00221, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 138ms/step - loss: 0.0022 - mean_absolute_error: 0.0359\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0347\n",
      "Epoch 00014: loss improved from 0.00221 to 0.00205, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.0021 - mean_absolute_error: 0.0347\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0333\n",
      "Epoch 00015: loss improved from 0.00205 to 0.00195, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 139ms/step - loss: 0.0020 - mean_absolute_error: 0.0333\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0321\n",
      "Epoch 00016: loss improved from 0.00195 to 0.00178, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 141ms/step - loss: 0.0018 - mean_absolute_error: 0.0321\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0349\n",
      "Epoch 00017: loss did not improve from 0.00178\n",
      "36/36 [==============================] - 5s 136ms/step - loss: 0.0021 - mean_absolute_error: 0.0349\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0336\n",
      "Epoch 00018: loss did not improve from 0.00178\n",
      "36/36 [==============================] - 5s 140ms/step - loss: 0.0019 - mean_absolute_error: 0.0336\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0321\n",
      "Epoch 00019: loss improved from 0.00178 to 0.00176, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 144ms/step - loss: 0.0018 - mean_absolute_error: 0.0321\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0302\n",
      "Epoch 00020: loss improved from 0.00176 to 0.00158, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 136ms/step - loss: 0.0016 - mean_absolute_error: 0.0302\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0315\n",
      "Epoch 00021: loss did not improve from 0.00158\n",
      "36/36 [==============================] - 5s 140ms/step - loss: 0.0017 - mean_absolute_error: 0.0315\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0313\n",
      "Epoch 00022: loss did not improve from 0.00158\n",
      "36/36 [==============================] - 5s 146ms/step - loss: 0.0017 - mean_absolute_error: 0.0313\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0308\n",
      "Epoch 00023: loss did not improve from 0.00158\n",
      "36/36 [==============================] - 5s 137ms/step - loss: 0.0017 - mean_absolute_error: 0.0308\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0298\n",
      "Epoch 00024: loss improved from 0.00158 to 0.00157, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 138ms/step - loss: 0.0016 - mean_absolute_error: 0.0298\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0291\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00025: loss improved from 0.00157 to 0.00153, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 137ms/step - loss: 0.0015 - mean_absolute_error: 0.0291\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0286\n",
      "Epoch 00026: loss improved from 0.00153 to 0.00150, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 138ms/step - loss: 0.0015 - mean_absolute_error: 0.0286\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0287\n",
      "Epoch 00027: loss improved from 0.00150 to 0.00145, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 138ms/step - loss: 0.0015 - mean_absolute_error: 0.0287\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0277\n",
      "Epoch 00028: loss improved from 0.00145 to 0.00137, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 141ms/step - loss: 0.0014 - mean_absolute_error: 0.0277\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0278\n",
      "Epoch 00029: loss improved from 0.00137 to 0.00135, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 137ms/step - loss: 0.0014 - mean_absolute_error: 0.0278\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0279\n",
      "Epoch 00030: loss did not improve from 0.00135\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0014 - mean_absolute_error: 0.0279\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0264\n",
      "Epoch 00031: loss improved from 0.00135 to 0.00128, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 136ms/step - loss: 0.0013 - mean_absolute_error: 0.0264\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0268\n",
      "Epoch 00032: loss did not improve from 0.00128\n",
      "36/36 [==============================] - 5s 139ms/step - loss: 0.0013 - mean_absolute_error: 0.0268\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0270\n",
      "Epoch 00033: loss did not improve from 0.00128\n",
      "36/36 [==============================] - 5s 136ms/step - loss: 0.0014 - mean_absolute_error: 0.0270\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0262\n",
      "Epoch 00034: loss improved from 0.00128 to 0.00125, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 141ms/step - loss: 0.0012 - mean_absolute_error: 0.0262\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0275\n",
      "Epoch 00035: loss did not improve from 0.00125\n",
      "36/36 [==============================] - 5s 140ms/step - loss: 0.0014 - mean_absolute_error: 0.0275\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0260\n",
      "Epoch 00036: loss improved from 0.00125 to 0.00121, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 136ms/step - loss: 0.0012 - mean_absolute_error: 0.0260\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0260\n",
      "Epoch 00037: loss did not improve from 0.00121\n",
      "36/36 [==============================] - 5s 134ms/step - loss: 0.0012 - mean_absolute_error: 0.0260\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0270\n",
      "Epoch 00038: loss did not improve from 0.00121\n",
      "36/36 [==============================] - 5s 141ms/step - loss: 0.0013 - mean_absolute_error: 0.0270\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0265\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00121\n",
      "36/36 [==============================] - 5s 135ms/step - loss: 0.0013 - mean_absolute_error: 0.0265\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0254\n",
      "Epoch 00040: loss improved from 0.00121 to 0.00118, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.0012 - mean_absolute_error: 0.0254\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0263\n",
      "Epoch 00041: loss did not improve from 0.00118\n",
      "36/36 [==============================] - 5s 140ms/step - loss: 0.0013 - mean_absolute_error: 0.0263\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0261\n",
      "Epoch 00042: loss did not improve from 0.00118\n",
      "36/36 [==============================] - 5s 134ms/step - loss: 0.0012 - mean_absolute_error: 0.0261\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0250\n",
      "Epoch 00043: loss improved from 0.00118 to 0.00116, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 137ms/step - loss: 0.0012 - mean_absolute_error: 0.0250\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0265\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00116\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.0013 - mean_absolute_error: 0.0265\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0259\n",
      "Epoch 00045: loss did not improve from 0.00116\n",
      "36/36 [==============================] - 5s 138ms/step - loss: 0.0012 - mean_absolute_error: 0.0259\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0252\n",
      "Epoch 00046: loss improved from 0.00116 to 0.00116, saving model to pesos.h5\n",
      "36/36 [==============================] - 5s 135ms/step - loss: 0.0012 - mean_absolute_error: 0.0252\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0258\n",
      "Epoch 00047: loss did not improve from 0.00116\n",
      "36/36 [==============================] - 5s 134ms/step - loss: 0.0012 - mean_absolute_error: 0.0258\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0262\n",
      "Epoch 00048: loss did not improve from 0.00116\n",
      "36/36 [==============================] - 5s 133ms/step - loss: 0.0012 - mean_absolute_error: 0.0262\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0252\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00116\n",
      "36/36 [==============================] - 5s 133ms/step - loss: 0.0012 - mean_absolute_error: 0.0252\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0253\n",
      "Epoch 00050: loss did not improve from 0.00116\n",
      "36/36 [==============================] - 5s 134ms/step - loss: 0.0012 - mean_absolute_error: 0.0253\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0264\n",
      "Epoch 00051: loss did not improve from 0.00116\n",
      "36/36 [==============================] - 5s 134ms/step - loss: 0.0012 - mean_absolute_error: 0.0264\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0259\n",
      "Epoch 00052: loss did not improve from 0.00116\n",
      "36/36 [==============================] - 5s 134ms/step - loss: 0.0012 - mean_absolute_error: 0.0259\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0254\n",
      "Epoch 00053: loss did not improve from 0.00116\n",
      "36/36 [==============================] - 5s 133ms/step - loss: 0.0012 - mean_absolute_error: 0.0254\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0260\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 00054: loss did not improve from 0.00116\n",
      "36/36 [==============================] - 5s 134ms/step - loss: 0.0012 - mean_absolute_error: 0.0260\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0258\n",
      "Epoch 00055: loss did not improve from 0.00116\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.0012 - mean_absolute_error: 0.0258\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0256\n",
      "Epoch 00056: loss did not improve from 0.00116\n",
      "36/36 [==============================] - 5s 135ms/step - loss: 0.0012 - mean_absolute_error: 0.0256\n",
      "Epoch 00056: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bff6002d30>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(monitor = 'loss', min_delta = 1e-10, patience = 10, verbose = 1)\n",
    "\n",
    "rlr = ReduceLROnPlateau(monitor = 'loss', factor = 0.2, patience = 5, verbose = 1)\n",
    "\n",
    "mcp = ModelCheckpoint(filepath = 'pesos.h5', monitor = 'loss', \n",
    "                      save_best_only = True, verbose = 1)\n",
    "\n",
    "regressor.fit(previsores, preco_real, epochs = 100, batch_size = 32,\n",
    "              callbacks = [es, rlr, mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50b41db1-8258-45da-bc25-332444fb724d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>16.190001</td>\n",
       "      <td>16.549999</td>\n",
       "      <td>16.190001</td>\n",
       "      <td>16.549999</td>\n",
       "      <td>16.516966</td>\n",
       "      <td>33461800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>16.490000</td>\n",
       "      <td>16.719999</td>\n",
       "      <td>16.370001</td>\n",
       "      <td>16.700001</td>\n",
       "      <td>16.666668</td>\n",
       "      <td>55940900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>16.780001</td>\n",
       "      <td>16.959999</td>\n",
       "      <td>16.620001</td>\n",
       "      <td>16.730000</td>\n",
       "      <td>16.696608</td>\n",
       "      <td>37064900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close    Volume\n",
       "0  2018-01-02  16.190001  16.549999  16.190001  16.549999  16.516966  33461800\n",
       "1  2018-01-03  16.490000  16.719999  16.370001  16.700001  16.666668  55940900\n",
       "2  2018-01-04  16.780001  16.959999  16.620001  16.730000  16.696608  37064900"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_teste = pd.read_csv('petr4_teste.csv')\n",
    "base_teste.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce0724b7-4aae-43ce-9311-9ef33fe5685e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-01-29</td>\n",
       "      <td>19.67</td>\n",
       "      <td>20.049999</td>\n",
       "      <td>19.570000</td>\n",
       "      <td>19.850000</td>\n",
       "      <td>19.810381</td>\n",
       "      <td>55726200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-01-30</td>\n",
       "      <td>19.77</td>\n",
       "      <td>19.770000</td>\n",
       "      <td>19.360001</td>\n",
       "      <td>19.490000</td>\n",
       "      <td>19.451097</td>\n",
       "      <td>46203000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>19.74</td>\n",
       "      <td>19.930000</td>\n",
       "      <td>19.680000</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>19.660681</td>\n",
       "      <td>41576600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date   Open       High        Low      Close  Adj Close    Volume\n",
       "19  2018-01-29  19.67  20.049999  19.570000  19.850000  19.810381  55726200\n",
       "20  2018-01-30  19.77  19.770000  19.360001  19.490000  19.451097  46203000\n",
       "21  2018-01-31  19.74  19.930000  19.680000  19.700001  19.660681  41576600"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_teste.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbfc77a2-044a-40ad-9712-f057e6929283",
   "metadata": {},
   "outputs": [],
   "source": [
    "preco_real_teste = base_teste.iloc[:, 1:2].values\n",
    "frames = [base, base_teste]\n",
    "base_completa = pd.concat(frames)\n",
    "base_completa = base_completa.drop('Date', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d566dea-3be9-4f4e-91d6-496088339ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "entradas = base_completa[len(base_completa) - len(base_teste) - 90:].values\n",
    "entradas = normalizador.transform(entradas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44e483bd-582e-4101-bfe2-a935496df53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88888f57-6cd6-42e9-92d8-c85b4c14a848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entradas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff6a5a34-896b-48f5-8268-d684790276d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 90, 6)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_teste = []\n",
    "for i in range(90, 112):\n",
    "    X_teste.append(entradas[i-90:i, 0:6])\n",
    "X_teste = np.array(X_teste)\n",
    "X_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2381374f-7d73-415c-b982-17d432ee6134",
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = regressor.predict(X_teste)\n",
    "previsoes = normalizador_previsao.inverse_transform(previsoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35c0dd23-12f4-461c-86bb-30991e83b7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.62474\n",
      "17.87454563636364\n"
     ]
    }
   ],
   "source": [
    "print(previsoes.mean())\n",
    "print(preco_real_teste.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97dc2132-f124-4f23-8228-26824a949b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(preco_real_teste, color = 'red', label = 'Preo real')\n",
    "plt.plot(previsoes, color = 'blue', label = 'Previses')\n",
    "plt.title('Previso preo das aes')\n",
    "plt.xlabel('Tempo')\n",
    "plt.ylabel('Valor Yahoo')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ef9890-7703-4062-a925-af5a51fa02f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_1",
   "language": "python",
   "name": "data_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
